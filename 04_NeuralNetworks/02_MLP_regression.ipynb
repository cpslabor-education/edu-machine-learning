{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "diabetes = sklearn.datasets.fetch_california_housing()\n",
    "X, Y = diabetes[\"data\"], diabetes[\"target\"]\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRegressionElu(nn.Module):\n",
    "    def __init__(self, input_dim=2, hidden_neurons=5, output_dim=3):\n",
    "        super(SimpleRegressionElu, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, hidden_neurons)\n",
    "        self.linear1 = nn.Linear(hidden_neurons, int(hidden_neurons/2))\n",
    "        self.linear2 = nn.Linear(int(hidden_neurons/2), int(hidden_neurons/2))\n",
    "        self.linear_out = nn.Linear(int(hidden_neurons/2), output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.elu = nn.ELU()\n",
    "        self.sf = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)        \n",
    "        x = self.elu(x)\n",
    "        x = self.linear1(x)        \n",
    "        x = self.elu(x)\n",
    "        x = self.linear2(x)        \n",
    "        x = self.relu(x)\n",
    "        x = self.linear_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "y_train_ = torch.from_numpy(y_train).type(torch.FloatTensor)\n",
    "X_test_ = torch.from_numpy(X_test).type(torch.FloatTensor)\n",
    "y_test_ = torch.from_numpy(y_test).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 100\n",
    "steps = X_train_.shape[0] // batch_size\n",
    "loss_func = nn.MSELoss()\n",
    "plt_iter = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            # initialize the weight tensor, here we use a normal distribution\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 completed, Loss 1.57334303855896 1.5711262226104736\n",
      "99 completed, Loss 1.573350191116333 1.571075439453125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x240ecbbac10>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = SimpleRegressionElu(input_dim=X.shape[1], output_dim=1, hidden_neurons=10)\n",
    "\n",
    "def train(net):\n",
    "    accuracy_list = []\n",
    "    \n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = 0.03)\n",
    "    weights_init(net)\n",
    "    all_losses = []\n",
    "    all_test_loss = []\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        all_train_pred = np.zeros((X_train.shape[0], 1))\n",
    "        current_loss = 0\n",
    "        for i in range(steps):\n",
    "            x_var = Variable(X_train_[i:i+batch_size], requires_grad=False)\n",
    "            y_var = Variable(y_train_[i:i+batch_size], requires_grad=False)\n",
    "            net.train()            \n",
    "            yhat = net(x_var)\n",
    "            loss = loss_func(yhat, y_var)            \n",
    "            loss.backward()\n",
    "            all_train_pred[i:i+batch_size] = yhat.detach().numpy().reshape(batch_size, 1)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            # Test loss\n",
    "            #\n",
    "            current_loss = (current_loss + loss)/2.0\n",
    "        if epoch %  plt_iter == 0:\n",
    "            all_losses.append(current_loss)\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            yhat = net(X_test_)\n",
    "            loss = loss_func(yhat, y_test_)\n",
    "            all_test_loss.append(loss)\n",
    "        if (epoch+1) % 50 == 0:\n",
    "            print(f\"{epoch} completed, Loss {current_loss} {loss}\")\n",
    "            \n",
    "    return all_losses, all_test_loss\n",
    "\n",
    "all_losses, all_test_loss = train(net)\n",
    "plt.plot(all_losses)\n",
    "plt.plot(all_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
